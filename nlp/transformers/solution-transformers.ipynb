{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10003865,"sourceType":"datasetVersion","datasetId":6157876}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"41b7905f-a070-4ffe-abfc-67fbcd2adaa9","cell_type":"markdown","source":"## TC3007C\n\n## Deep Learning\n\n## Transformers\n\n### Team Members\n\n- [Carlos Salguero](https://github.com/salgue441)\n- [Diego Perdomo](https://github.com/DiegoPerdomoS)\n- [Arturo Rendón](https://github.com/00sen)\n- [José Riosmena](https://github.com/Riosmena)\n- [Dafne Fernández](https://github.com/Dafne224)\n\n#### Activity 3: Implementing a Translator\n\n- Objective\n\nTo understand the Transformer Architecture by Implementing a translator.\n\n- Instructions\n\n  This activity requires submission in teams. While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n\n  Follow the provided code. The code already implements a transformer from scratch as explained in [this video](https://youtu.be/XefFj4rLHgU)\n\n  Since the provided code already implements a simple translator, your job for this assignment is to understand it fully, and document it using pictures, figures, and markdown cells. You should test your translator with at least 10 sentences. The dataset used for this task was obtained from [Tatoeba, a large dataset of sentences and translations](https://tatoeba.org/en/downloads).\n\n- Evaluation Criteria\n\n  - Code Readability and Comments\n  - Traning a translator\n  - Translating at least 10 sentences.\n\n- Submission\n\nSubmit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.","metadata":{}},{"id":"17f54c65","cell_type":"markdown","source":"#### Script to convert csv to text file","metadata":{"heading_collapsed":true}},{"id":"8f02c0c2","cell_type":"code","source":"import pandas as pd","metadata":{"hidden":true,"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:45.979901Z","iopub.execute_input":"2024-11-25T00:52:45.980233Z","iopub.status.idle":"2024-11-25T00:52:46.289566Z","shell.execute_reply.started":"2024-11-25T00:52:45.980206Z","shell.execute_reply":"2024-11-25T00:52:46.288905Z"}},"outputs":[],"execution_count":1},{"id":"f6fbfaf8","cell_type":"code","source":"PATH = \"/kaggle/input/english-spanish/eng-spa.tsv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:46.290940Z","iopub.execute_input":"2024-11-25T00:52:46.291252Z","iopub.status.idle":"2024-11-25T00:52:46.294779Z","shell.execute_reply.started":"2024-11-25T00:52:46.291227Z","shell.execute_reply":"2024-11-25T00:52:46.293976Z"}},"outputs":[],"execution_count":2},{"id":"887b425f","cell_type":"code","source":"df = pd.read_csv(PATH, sep=\"\\t\", on_bad_lines=\"skip\")\nprint(f\"Number of columns: {df.shape[1]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:46.295758Z","iopub.execute_input":"2024-11-25T00:52:46.295991Z","iopub.status.idle":"2024-11-25T00:52:47.117382Z","shell.execute_reply.started":"2024-11-25T00:52:46.295968Z","shell.execute_reply":"2024-11-25T00:52:47.116444Z"}},"outputs":[{"name":"stdout","text":"Number of columns: 4\n","output_type":"stream"}],"execution_count":3},{"id":"ef686fb5","cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:47.119591Z","iopub.execute_input":"2024-11-25T00:52:47.120004Z","iopub.status.idle":"2024-11-25T00:52:47.136123Z","shell.execute_reply.started":"2024-11-25T00:52:47.119966Z","shell.execute_reply":"2024-11-25T00:52:47.135292Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   1276                              Let's try something.     2481  \\\n0  1277                            I have to go to sleep.     2482   \n1  1280  Today is June 18th and it is Muiriel's birthday!     2485   \n2  1280  Today is June 18th and it is Muiriel's birthday!  1130137   \n3  1282                                Muiriel is 20 now.     2487   \n4  1282                                Muiriel is 20 now.  1130133   \n\n                                   ¡Intentemos algo!  \n0                           Tengo que irme a dormir.  \n1  ¡Hoy es 18 de junio y es el cumpleaños de Muir...  \n2  ¡Hoy es el 18 de junio y es el cumpleaños de M...  \n3                      Ahora, Muiriel tiene 20 años.  \n4                       Muiriel tiene 20 años ahora.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1276</th>\n      <th>Let's try something.</th>\n      <th>2481</th>\n      <th>¡Intentemos algo!</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1277</td>\n      <td>I have to go to sleep.</td>\n      <td>2482</td>\n      <td>Tengo que irme a dormir.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1280</td>\n      <td>Today is June 18th and it is Muiriel's birthday!</td>\n      <td>2485</td>\n      <td>¡Hoy es 18 de junio y es el cumpleaños de Muir...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1280</td>\n      <td>Today is June 18th and it is Muiriel's birthday!</td>\n      <td>1130137</td>\n      <td>¡Hoy es el 18 de junio y es el cumpleaños de M...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1282</td>\n      <td>Muiriel is 20 now.</td>\n      <td>2487</td>\n      <td>Ahora, Muiriel tiene 20 años.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1282</td>\n      <td>Muiriel is 20 now.</td>\n      <td>1130133</td>\n      <td>Muiriel tiene 20 años ahora.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"id":"673348bc","cell_type":"code","source":"eng_spa_cols = df.iloc[:, [1, 3]]\neng_spa_cols[\"length\"] = eng_spa_cols.iloc[:, 0].str.len()\neng_spa_cols = eng_spa_cols.sort_values(by=\"length\")\neng_spa_cols = eng_spa_cols.drop(columns=[\"length\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:47.137030Z","iopub.execute_input":"2024-11-25T00:52:47.137279Z","iopub.status.idle":"2024-11-25T00:52:47.271589Z","shell.execute_reply.started":"2024-11-25T00:52:47.137256Z","shell.execute_reply":"2024-11-25T00:52:47.270665Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/4043921570.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  eng_spa_cols[\"length\"] = eng_spa_cols.iloc[:, 0].str.len()\n","output_type":"stream"}],"execution_count":5},{"id":"b03cdb35","cell_type":"markdown","source":"Saving the output file locally.","metadata":{}},{"id":"787d9408","cell_type":"code","source":"output_file_path = \"/kaggle/working/eng-spa4.txt\"\neng_spa_cols.to_csv(output_file_path, sep=\"\\t\", index=False, header=False)","metadata":{"hidden":true,"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:47.272970Z","iopub.execute_input":"2024-11-25T00:52:47.273232Z","iopub.status.idle":"2024-11-25T00:52:47.913031Z","shell.execute_reply.started":"2024-11-25T00:52:47.273206Z","shell.execute_reply":"2024-11-25T00:52:47.912300Z"}},"outputs":[],"execution_count":6},{"id":"7d468e9a","cell_type":"markdown","source":"## Transformer - Attention is all you need","metadata":{}},{"id":"d5dcf681","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom collections import Counter\nimport math\nimport numpy as np\nimport re\nfrom typing import List, Tuple","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:47.913942Z","iopub.execute_input":"2024-11-25T00:52:47.914168Z","iopub.status.idle":"2024-11-25T00:52:50.903752Z","shell.execute_reply.started":"2024-11-25T00:52:47.914146Z","shell.execute_reply":"2024-11-25T00:52:50.902988Z"}},"outputs":[],"execution_count":7},{"id":"fbcc6201","cell_type":"code","source":"torch.manual_seed(23)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:50.904778Z","iopub.execute_input":"2024-11-25T00:52:50.905248Z","iopub.status.idle":"2024-11-25T00:52:50.914456Z","shell.execute_reply.started":"2024-11-25T00:52:50.905203Z","shell.execute_reply":"2024-11-25T00:52:50.913658Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7af90a73b450>"},"metadata":{}}],"execution_count":8},{"id":"2c2cbd17","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:50.915510Z","iopub.execute_input":"2024-11-25T00:52:50.915843Z","iopub.status.idle":"2024-11-25T00:52:50.951003Z","shell.execute_reply.started":"2024-11-25T00:52:50.915819Z","shell.execute_reply":"2024-11-25T00:52:50.950150Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":9},{"id":"1245cbbe","cell_type":"markdown","source":"Max sequence length","metadata":{}},{"id":"9c6623a1","cell_type":"code","source":"MAX_SEQ_LEN = 128","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:50.953686Z","iopub.execute_input":"2024-11-25T00:52:50.953975Z","iopub.status.idle":"2024-11-25T00:52:50.961205Z","shell.execute_reply.started":"2024-11-25T00:52:50.953951Z","shell.execute_reply":"2024-11-25T00:52:50.960527Z"}},"outputs":[],"execution_count":10},{"id":"b136fbad","cell_type":"markdown","source":"## Positional Embedding","metadata":{}},{"id":"c460df01","cell_type":"code","source":"class PositionalEmbedding(nn.Module):\n    \"\"\"\n    Positional embedding module designed to add positional information\n    to the input tokens.\n\n    Attributes:\n        pos_embeded_matrix (torch.Tensor): The positional embedding matrix\n    \"\"\"\n\n    def __init__(self, d_model, max_seq_len=MAX_SEQ_LEN):\n        super().__init__()\n        self.pos_embed_matrix = torch.zeros(max_seq_len, d_model, device=device)\n\n        token_pos = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(\n            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n        )\n\n        self.pos_embed_matrix[:, 0::2] = torch.sin(token_pos * div_term)\n        self.pos_embed_matrix[:, 1::2] = torch.cos(token_pos * div_term)\n        self.pos_embed_matrix = self.pos_embed_matrix.unsqueeze(0).transpose(0, 1)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Forward pass of the PositionalEmbedding module.\n\n        Args:\n            x (torch.Tensor): The input tensor\n\n        Returns:\n            torch.Tensor: The input tensor with positional information added\n        \"\"\"\n\n        return x + self.pos_embed_matrix[: x.size(0), :]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:50.962135Z","iopub.execute_input":"2024-11-25T00:52:50.962377Z","iopub.status.idle":"2024-11-25T00:52:50.974168Z","shell.execute_reply.started":"2024-11-25T00:52:50.962353Z","shell.execute_reply":"2024-11-25T00:52:50.973355Z"}},"outputs":[],"execution_count":11},{"id":"0011288f","cell_type":"markdown","source":"## Multi-Head Attention","metadata":{}},{"id":"5725a88a","cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    \"\"\"\n    Multi-head attention module designed to compute the attention\n    scores between the query, key, and value tensors.\n\n    Attributes:\n        d_v (int): The dimension of the value tensor\n        d_k (int): The dimension of the key tensor\n        num_heads (int): The number of heads\n        W_q (nn.Linear): The linear projection for the query tensor\n        W_k (nn.Linear): The linear projection for the key tensor\n        W_v (nn.Linear): The linear projection for the value tensor\n        W_o (nn.Linear): The linear projection for the output tensor\n    \"\"\"\n\n    def __init__(self, d_model=512, num_heads=8):\n        super().__init__()\n        assert d_model % num_heads == 0, \"Embedding size not compatible with num heads\"\n\n        # Calculate the dimension of each head\n        self.d_v = d_model // num_heads\n        self.d_k = self.d_v\n        self.num_heads = num_heads\n\n        # Define linear projections for query, key, value, and output\n        self.W_q = nn.Linear(d_model, d_model)\n        self.W_k = nn.Linear(d_model, d_model)\n        self.W_v = nn.Linear(d_model, d_model)\n        self.W_o = nn.Linear(d_model, d_model)\n\n    def forward(\n        self, Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor, mask=None\n    ) -> torch.Tensor:\n        \"\"\"\n        Forward pass of the MultiHeadAttention module.\n\n        Args:\n            Q (torch.Tensor): The query tensor\n            K (torch.Tensor): The key tensor\n            V (torch.Tensor): The value tensor\n            mask (torch.Tensor): The mask tensor\n\n        Returns:\n            torch.Tensor: The output tensor\n        \"\"\"\n\n        batch_size = Q.size(0)\n\n        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n\n        weighted_values, attention = self.scale_dot_product(Q, K, V, mask)\n        weighted_values = (\n            weighted_values.transpose(1, 2)\n            .contiguous()\n            .view(batch_size, -1, self.num_heads * self.d_k)\n        )\n\n        weighted_values = self.W_o(weighted_values)\n        return weighted_values, attention\n\n    def scale_dot_product(\n        self, Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor, mask=None\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Dot product attention with scaling and masking.\n\n        Args:\n            Q (torch.Tensor): The query tensor\n            K (torch.Tensor): The key tensor\n            V (torch.Tensor): The value tensor\n            mask (torch.Tensor): The mask tensor\n\n        Returns:\n            torch.Tensor: The weighted values\n            torch.Tensor: The attention scores\n        \"\"\"\n\n        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n\n        attention = F.softmax(scores, dim=-1)\n        weighted_values = torch.matmul(attention, V)\n\n        return weighted_values, attention","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:50.975277Z","iopub.execute_input":"2024-11-25T00:52:50.976043Z","iopub.status.idle":"2024-11-25T00:52:50.988109Z","shell.execute_reply.started":"2024-11-25T00:52:50.976004Z","shell.execute_reply":"2024-11-25T00:52:50.987386Z"}},"outputs":[],"execution_count":12},{"id":"f32db8b2","cell_type":"markdown","source":"## Position-wise Feed-Forward Networks","metadata":{}},{"id":"3587ab1c","cell_type":"code","source":"class PositionFeedForward(nn.Module):\n    \"\"\"\n    Position-wise feedforward module designed to apply two linear\n    transformations with a ReLU activation in between.\n\n    Attributes:\n        linear1 (nn.Linear): The first linear transformation\n        linear2 (nn.Linear): The second linear transformation\n    \"\"\"\n\n    def __init__(self, d_model, d_ff):\n        super().__init__()\n\n        self.linear1 = nn.Linear(d_model, d_ff)\n        self.linear2 = nn.Linear(d_ff, d_model)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Forward pass of the PositionFeedForward module.\n\n        Args:\n            x (torch.Tensor): The input tensor\n\n        Returns:\n            torch.Tensor: The output tensor\n        \"\"\"\n\n        return self.linear2(F.relu(self.linear1(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:50.989021Z","iopub.execute_input":"2024-11-25T00:52:50.989253Z","iopub.status.idle":"2024-11-25T00:52:51.003326Z","shell.execute_reply.started":"2024-11-25T00:52:50.989230Z","shell.execute_reply":"2024-11-25T00:52:51.002482Z"}},"outputs":[],"execution_count":13},{"id":"78100bce","cell_type":"markdown","source":"## Encoder Sublayer","metadata":{}},{"id":"9354f636","cell_type":"code","source":"class EncoderSubLayer(nn.Module):\n    \"\"\"\n    Encoded sublayer module designed to apply multi-head attention\n    and position-wise feedforward operations.\n\n    Attributes:\n        self_attn (MultiHeadAttention): The multi-head attention module\n        ffn (PositionFeedForward): The position-wise feedforward module\n        norm1 (nn.LayerNorm): The first layer normalization module\n        norm2 (nn.LayerNorm): The second layer normalization module\n        dropout1 (nn.Dropout): The first dropout module\n        dropout2 (nn.Dropout): The second dropout\n    \"\"\"\n\n    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n        super().__init__()\n\n        self.self_attn = MultiHeadAttention(d_model, num_heads)\n        self.ffn = PositionFeedForward(d_model, d_ff)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n\n    def forward(self, x: torch.Tensor, mask=None) -> torch.Tensor:\n        \"\"\"\n        Forward pass of the EncoderSubLayer module.\n\n        Args:\n            x (torch.Tensor): The input tensor\n            mask (torch.Tensor): The mask tensor\n\n        Returns:\n            torch.Tensor: The output tensor\n        \"\"\"\n\n        attention_score, _ = self.self_attn(x, x, x, mask)\n        x = x + self.dropout1(attention_score)\n        x = self.norm1(x)\n\n        x = x + self.dropout2(self.ffn(x))\n        return self.norm2(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:51.004291Z","iopub.execute_input":"2024-11-25T00:52:51.004621Z","iopub.status.idle":"2024-11-25T00:52:51.015778Z","shell.execute_reply.started":"2024-11-25T00:52:51.004566Z","shell.execute_reply":"2024-11-25T00:52:51.014949Z"}},"outputs":[],"execution_count":14},{"id":"4477a407","cell_type":"markdown","source":"## Encoder","metadata":{}},{"id":"82a6aaf9","cell_type":"code","source":"class Encoder(nn.Module):\n    \"\"\"\n    Encoder module designed to apply multiple EncoderSubLayer modules.\n\n    Attributes:\n        layers (nn.ModuleList): The list of EncoderSubLayer modules\n        norm (nn.LayerNorm): The layer normalization module\n    \"\"\"\n\n    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n        super().__init__()\n\n        self.layers = nn.ModuleList(\n            [\n                EncoderSubLayer(d_model, num_heads, d_ff, dropout)\n                for _ in range(num_layers)\n            ]\n        )\n\n        self.norm = nn.LayerNorm(d_model)\n\n    def forward(self, x: torch.Tensor, mask=None) -> torch.Tensor:\n        \"\"\"\n        Forward pass of the Encoder module.\n\n        Args:\n            x (torch.Tensor): The input tensor\n            mask (torch.Tensor): The mask tensor\n\n        Returns:\n            torch.Tensor: The output tensor\n        \"\"\"\n\n        for layer in self.layers:\n            x = layer(x, mask)\n\n        return self.norm(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:51.016797Z","iopub.execute_input":"2024-11-25T00:52:51.017035Z","iopub.status.idle":"2024-11-25T00:52:51.032380Z","shell.execute_reply.started":"2024-11-25T00:52:51.017013Z","shell.execute_reply":"2024-11-25T00:52:51.031541Z"}},"outputs":[],"execution_count":15},{"id":"0a9245cc","cell_type":"markdown","source":"## Decoder Sublayer","metadata":{}},{"id":"6f8cc2fe","cell_type":"code","source":"class DecoderSubLayer(nn.Module):\n    \"\"\"\n    Decode sublayer module designed to apply multi-head attention\n    and position-wise feedforward operations.\n\n    Attributes:\n        self_attn (MultiHeadAttention): The multi-head attention module\n        cross_attn (MultiHeadAttention): The multi-head attention module\n        ffn (PositionFeedForward): The position-wise feedforward module\n        norm1 (nn.LayerNorm): The first layer normalization module\n        norm2 (nn.LayerNorm): The second layer normalization module\n        norm3 (nn.LayerNorm): The third layer normalization module\n        dropout1 (nn.Dropout): The first dropout module\n        dropout2 (nn.Dropout): The second dropout module\n        dropout3 (nn.Dropout): The third\n    \"\"\"\n\n    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n        super().__init__()\n\n        self.self_attn = MultiHeadAttention(d_model, num_heads)\n        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n        self.feed_forward = PositionFeedForward(d_model, d_ff)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n        self.dropout3 = nn.Dropout(dropout)\n\n    def forward(\n        self, x: torch.Tensor, encoder_output, target_mask=None, encoder_mask=None\n    ) -> torch.Tensor:\n        \"\"\"\n        Forward pass of the DecoderSubLayer module.\n\n        Args:\n            x (torch.Tensor): The input tensor\n            encoder_output (torch.Tensor): The encoder output tensor\n            target_mask (torch.Tensor): The target mask tensor\n            encoder_mask (torch.Tensor): The encoder mask tensor\n\n        Returns:\n            torch.Tensor: The output tensor\n        \"\"\"\n\n        attention_score, _ = self.self_attn(x, x, x, target_mask)\n        x = x + self.dropout1(attention_score)\n        x = self.norm1(x)\n\n        encoder_attn, _ = self.cross_attn(\n            x, encoder_output, encoder_output, encoder_mask\n        )\n        x = x + self.dropout2(encoder_attn)\n        x = self.norm2(x)\n\n        ff_output = self.feed_forward(x)\n        x = x + self.dropout3(ff_output)\n        return self.norm3(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:51.033546Z","iopub.execute_input":"2024-11-25T00:52:51.033834Z","iopub.status.idle":"2024-11-25T00:52:51.046289Z","shell.execute_reply.started":"2024-11-25T00:52:51.033793Z","shell.execute_reply":"2024-11-25T00:52:51.045660Z"}},"outputs":[],"execution_count":16},{"id":"7c4a8f32","cell_type":"markdown","source":"## Decoder Module","metadata":{}},{"id":"3103d45f","cell_type":"code","source":"class Decoder(nn.Module):\n    \"\"\"\n    Decoder module designed to apply multiple DecoderSubLayer modules.\n\n    Attributes:\n        layers (nn.ModuleList): The list of DecoderSubLayer modules\n        norm (nn.LayerNorm): The layer normalization module\n    \"\"\"\n\n    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n        super().__init__()\n\n        self.layers = nn.ModuleList(\n            [\n                DecoderSubLayer(d_model, num_heads, d_ff, dropout)\n                for _ in range(num_layers)\n            ]\n        )\n        self.norm = nn.LayerNorm(d_model)\n\n    def forward(\n        self, x: torch.Tensor, encoder_output, target_mask, encoder_mask\n    ) -> torch.Tensor:\n        \"\"\"\n        Forward pass of the Decoder module.\n\n        Args:\n            x (torch.Tensor): The input tensor\n            encoder_output (torch.Tensor): The encoder output tensor\n            target_mask (torch.Tensor): The target mask tensor\n            encoder_mask (torch.Tensor): The encoder mask tensor\n\n        Returns:\n            torch.Tensor: The output tensor\n        \"\"\"\n\n        for layer in self.layers:\n            x = layer(x, encoder_output, target_mask, encoder_mask)\n\n        return self.norm(x)","metadata":{"code_folding":[30,94],"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:51.047240Z","iopub.execute_input":"2024-11-25T00:52:51.047551Z","iopub.status.idle":"2024-11-25T00:52:51.060042Z","shell.execute_reply.started":"2024-11-25T00:52:51.047515Z","shell.execute_reply":"2024-11-25T00:52:51.059316Z"}},"outputs":[],"execution_count":17},{"id":"d8b532de","cell_type":"markdown","source":"## Transformer","metadata":{}},{"id":"61070162","cell_type":"code","source":"class Transformer(nn.Module):\n    \"\"\"\n    Transformer module designed to translate sequences from one language to\n    another using an encoder and decoder architecture.\n\n    Attributes:\n        encoder_embedding (nn.Embedding): The embedding layer for the encoder\n        decoder_embedding (nn.Embedding): The embedding layer for the decoder\n        pos_embedding (PositionalEmbedding): The positional embedding layer\n        encoder (Encoder): The encoder module\n        decoder (Decoder): The decoder module\n        output_layer (nn.Linear): The output layer\n    \"\"\"\n\n    def __init__(\n        self,\n        d_model,\n        num_heads,\n        d_ff,\n        num_layers,\n        input_vocab_size,\n        target_vocab_size,\n        max_len=MAX_SEQ_LEN,\n        dropout=0.1,\n    ):\n        super().__init__()\n\n        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n        self.pos_embedding = PositionalEmbedding(d_model, max_len)\n        self.encoder = Encoder(d_model, num_heads, d_ff, num_layers, dropout)\n        self.decoder = Decoder(d_model, num_heads, d_ff, num_layers, dropout)\n        self.output_layer = nn.Linear(d_model, target_vocab_size)\n\n    def forward(self, source: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Forward pass of the Transformer module.\n\n        Args:\n            source (torch.Tensor): The source tensor\n            target (torch.Tensor): The target tensor\n\n        Returns:\n            torch.Tensor: The output tensor\n        \"\"\"\n\n        source_mask, target_mask = self.mask(source, target)\n        source = self.encoder_embedding(source) * math.sqrt(\n            self.encoder_embedding.embedding_dim\n        )\n        source = self.pos_embedding(source)\n\n        encoder_output = self.encoder(source, source_mask)\n        target = self.decoder_embedding(target) * math.sqrt(\n            self.decoder_embedding.embedding_dim\n        )\n        target = self.pos_embedding(target)\n\n        output = self.decoder(target, encoder_output, target_mask, source_mask)\n        return self.output_layer(output)\n\n    def mask(\n        self, source: torch.Tensor, target: torch.Tensor\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Masks the source and target tensors to prevent the model from\n        attending to the padding tokens.\n\n        Args:\n            source (torch.Tensor): The source tensor\n            target (torch.Tensor): The target tensor\n\n        Returns:\n            List[torch.Tensor]: The source and target masks\n        \"\"\"\n\n        source_mask = (source != 0).unsqueeze(1).unsqueeze(2)\n        target_mask = (target != 0).unsqueeze(1).unsqueeze(2)\n\n        size = target.size(1)\n        no_mask = torch.tril(torch.ones((1, size, size), device=device)).bool()\n        target_mask = target_mask & no_mask\n\n        return source_mask, target_mask","metadata":{"code_folding":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:51.061096Z","iopub.execute_input":"2024-11-25T00:52:51.061342Z","iopub.status.idle":"2024-11-25T00:52:51.073260Z","shell.execute_reply.started":"2024-11-25T00:52:51.061320Z","shell.execute_reply":"2024-11-25T00:52:51.072562Z"}},"outputs":[],"execution_count":18},{"id":"6da6b2d4","cell_type":"markdown","source":"## Simple test","metadata":{"heading_collapsed":true}},{"id":"f28f2cc4","cell_type":"markdown","source":"### Sequence parameters","metadata":{}},{"id":"d40581d6","cell_type":"code","source":"seq_len_source = 10\nseq_len_target = 10\nbatch_size = 2\ninput_vocab_size = 50\ntarget_vocab_size = 50","metadata":{"hidden":true,"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:51.074157Z","iopub.execute_input":"2024-11-25T00:52:51.074470Z","iopub.status.idle":"2024-11-25T00:52:51.092887Z","shell.execute_reply.started":"2024-11-25T00:52:51.074433Z","shell.execute_reply":"2024-11-25T00:52:51.092152Z"}},"outputs":[],"execution_count":19},{"id":"24939149","cell_type":"markdown","source":"### Input & Output","metadata":{}},{"id":"8f2f6d73","cell_type":"code","source":"source = torch.randint(1, input_vocab_size, (batch_size, seq_len_source))\ntarget = torch.randint(1, target_vocab_size, (batch_size, seq_len_target))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:51.093847Z","iopub.execute_input":"2024-11-25T00:52:51.094165Z","iopub.status.idle":"2024-11-25T00:52:51.119205Z","shell.execute_reply.started":"2024-11-25T00:52:51.094130Z","shell.execute_reply":"2024-11-25T00:52:51.118644Z"}},"outputs":[],"execution_count":20},{"id":"502a43a9","cell_type":"markdown","source":"### Model Hyperparameters","metadata":{}},{"id":"259d56a4","cell_type":"code","source":"d_model = 512\nnum_heads = 8\nd_ff = 2048\nnum_layers = 6","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:51.120090Z","iopub.execute_input":"2024-11-25T00:52:51.120417Z","iopub.status.idle":"2024-11-25T00:52:51.124142Z","shell.execute_reply.started":"2024-11-25T00:52:51.120378Z","shell.execute_reply":"2024-11-25T00:52:51.123287Z"}},"outputs":[],"execution_count":21},{"id":"fb3732c5","cell_type":"markdown","source":"## Model Execution","metadata":{}},{"id":"9e4254c6","cell_type":"code","source":"model = Transformer(\n    d_model,\n    num_heads,\n    d_ff,\n    num_layers,\n    input_vocab_size,\n    target_vocab_size,\n    max_len=MAX_SEQ_LEN,\n    dropout=0.1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:51.125030Z","iopub.execute_input":"2024-11-25T00:52:51.125275Z","iopub.status.idle":"2024-11-25T00:52:51.811350Z","shell.execute_reply.started":"2024-11-25T00:52:51.125233Z","shell.execute_reply":"2024-11-25T00:52:51.810662Z"}},"outputs":[],"execution_count":22},{"id":"6323faa9","cell_type":"code","source":"model = model.to(device)\nsource = source.to(device)\ntarget = target.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:51.812240Z","iopub.execute_input":"2024-11-25T00:52:51.812463Z","iopub.status.idle":"2024-11-25T00:52:51.884197Z","shell.execute_reply.started":"2024-11-25T00:52:51.812440Z","shell.execute_reply":"2024-11-25T00:52:51.883580Z"}},"outputs":[],"execution_count":23},{"id":"4fb96380","cell_type":"markdown","source":"Computing the model output","metadata":{}},{"id":"b71ed8be","cell_type":"code","source":"output = model(source, target)\nprint(f\"ouput.shape {output.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:51.885011Z","iopub.execute_input":"2024-11-25T00:52:51.885247Z","iopub.status.idle":"2024-11-25T00:52:52.257798Z","shell.execute_reply.started":"2024-11-25T00:52:51.885223Z","shell.execute_reply":"2024-11-25T00:52:52.256937Z"}},"outputs":[{"name":"stdout","text":"ouput.shape torch.Size([2, 10, 50])\n","output_type":"stream"}],"execution_count":24},{"id":"0f4b2910","cell_type":"markdown","source":"## Translator Eng-Spa","metadata":{}},{"id":"75dff394","cell_type":"markdown","source":"### English File Reading","metadata":{}},{"id":"869a7244","cell_type":"code","source":"PATH = \"/kaggle/working/eng-spa4.txt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:52.258963Z","iopub.execute_input":"2024-11-25T00:52:52.259651Z","iopub.status.idle":"2024-11-25T00:52:52.263514Z","shell.execute_reply.started":"2024-11-25T00:52:52.259578Z","shell.execute_reply":"2024-11-25T00:52:52.262659Z"}},"outputs":[],"execution_count":25},{"id":"d0af1eba","cell_type":"code","source":"with open(PATH, \"r\", encoding=\"utf-8\") as f:\n    lines = f.readlines()\n\neng_spa_pairs = [line.strip().split(\"\\t\") for line in lines if \"\\t\" in line]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:52.264503Z","iopub.execute_input":"2024-11-25T00:52:52.265004Z","iopub.status.idle":"2024-11-25T00:52:52.737774Z","shell.execute_reply.started":"2024-11-25T00:52:52.264979Z","shell.execute_reply":"2024-11-25T00:52:52.737059Z"}},"outputs":[],"execution_count":26},{"id":"c930226f","cell_type":"code","source":"eng_spa_pairs[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:52.738847Z","iopub.execute_input":"2024-11-25T00:52:52.739171Z","iopub.status.idle":"2024-11-25T00:52:52.745404Z","shell.execute_reply.started":"2024-11-25T00:52:52.739136Z","shell.execute_reply":"2024-11-25T00:52:52.744569Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[['Hi.', 'Hola.'],\n ['No.', 'No.'],\n ['Go.', 'Vaya.'],\n ['Go!', 'Vete'],\n ['No!', '¡No!'],\n ['Go!', '¡Fuera!'],\n ['Go!', '¡Sal!'],\n ['Go!', '¡Ve!'],\n ['Ah!', '¡Anda!'],\n ['Go!', 'Váyase']]"},"metadata":{}}],"execution_count":27},{"id":"095f4037","cell_type":"code","source":"eng_sentences = [pair[0] for pair in eng_spa_pairs]\nspa_sentences = [pair[1] for pair in eng_spa_pairs]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:52.749620Z","iopub.execute_input":"2024-11-25T00:52:52.749921Z","iopub.status.idle":"2024-11-25T00:52:52.789241Z","shell.execute_reply.started":"2024-11-25T00:52:52.749871Z","shell.execute_reply":"2024-11-25T00:52:52.788651Z"}},"outputs":[],"execution_count":28},{"id":"0d9e1c95","cell_type":"code","source":"print(eng_sentences[:10])\nprint(spa_sentences[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:52.790253Z","iopub.execute_input":"2024-11-25T00:52:52.790908Z","iopub.status.idle":"2024-11-25T00:52:52.795150Z","shell.execute_reply.started":"2024-11-25T00:52:52.790863Z","shell.execute_reply":"2024-11-25T00:52:52.794273Z"}},"outputs":[{"name":"stdout","text":"['Hi.', 'No.', 'Go.', 'Go!', 'No!', 'Go!', 'Go!', 'Go!', 'Ah!', 'Go!']\n['Hola.', 'No.', 'Vaya.', 'Vete', '¡No!', '¡Fuera!', '¡Sal!', '¡Ve!', '¡Anda!', 'Váyase']\n","output_type":"stream"}],"execution_count":29},{"id":"60d11478","cell_type":"code","source":"def preprocess_sentence(sentence: str) -> str:\n    \"\"\"\n    Function to preprocess a sentence by converting to lowercase, removing special characters,\n    and adding start and end tokens.\n\n    Args:\n        sentence (str): The input sentence\n\n    Returns:\n        str: The preprocessed sentence\n    \"\"\"\n\n    sentence = sentence.lower().strip()\n    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n\n    sentence = re.sub(r\"[á]+\", \"a\", sentence)\n    sentence = re.sub(r\"[é]+\", \"e\", sentence)\n    sentence = re.sub(r\"[í]+\", \"i\", sentence)\n    sentence = re.sub(r\"[ó]+\", \"o\", sentence)\n    sentence = re.sub(r\"[ú]+\", \"u\", sentence)\n\n    sentence = re.sub(r\"[^a-z]+\", \" \", sentence)\n    sentence = sentence.strip()\n    sentence = \"<sos> \" + sentence + \" <eos>\"\n\n    return sentence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:52.796116Z","iopub.execute_input":"2024-11-25T00:52:52.796380Z","iopub.status.idle":"2024-11-25T00:52:52.812786Z","shell.execute_reply.started":"2024-11-25T00:52:52.796346Z","shell.execute_reply":"2024-11-25T00:52:52.812063Z"}},"outputs":[],"execution_count":30},{"id":"8890975f","cell_type":"markdown","source":"### Sample Processing","metadata":{}},{"id":"478f673b","cell_type":"code","source":"s1 = \"¿Hola @ cómo estás? 123\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:52.813698Z","iopub.execute_input":"2024-11-25T00:52:52.813944Z","iopub.status.idle":"2024-11-25T00:52:52.826076Z","shell.execute_reply.started":"2024-11-25T00:52:52.813920Z","shell.execute_reply":"2024-11-25T00:52:52.825405Z"}},"outputs":[],"execution_count":31},{"id":"96ac79c5","cell_type":"code","source":"print(s1)\nprint(preprocess_sentence(s1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:52.826894Z","iopub.execute_input":"2024-11-25T00:52:52.827137Z","iopub.status.idle":"2024-11-25T00:52:52.837659Z","shell.execute_reply.started":"2024-11-25T00:52:52.827098Z","shell.execute_reply":"2024-11-25T00:52:52.836805Z"}},"outputs":[{"name":"stdout","text":"¿Hola @ cómo estás? 123\n<sos> hola como estas <eos>\n","output_type":"stream"}],"execution_count":32},{"id":"d9fc9c4d","cell_type":"code","source":"eng_sentences = [preprocess_sentence(sentence) for sentence in eng_sentences]\nspa_sentences = [preprocess_sentence(sentence) for sentence in spa_sentences]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:52.838830Z","iopub.execute_input":"2024-11-25T00:52:52.839085Z","iopub.status.idle":"2024-11-25T00:52:59.371020Z","shell.execute_reply.started":"2024-11-25T00:52:52.839062Z","shell.execute_reply":"2024-11-25T00:52:59.370012Z"}},"outputs":[],"execution_count":33},{"id":"f7a3b18d","cell_type":"code","source":"spa_sentences[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:59.371995Z","iopub.execute_input":"2024-11-25T00:52:59.372268Z","iopub.status.idle":"2024-11-25T00:52:59.377780Z","shell.execute_reply.started":"2024-11-25T00:52:59.372241Z","shell.execute_reply":"2024-11-25T00:52:59.376823Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"['<sos> hola <eos>',\n '<sos> no <eos>',\n '<sos> vaya <eos>',\n '<sos> vete <eos>',\n '<sos> no <eos>',\n '<sos> fuera <eos>',\n '<sos> sal <eos>',\n '<sos> ve <eos>',\n '<sos> anda <eos>',\n '<sos> vayase <eos>']"},"metadata":{}}],"execution_count":34},{"id":"97931cd3","cell_type":"code","source":"def build_vocab(sentences: List[str]) -> dict:\n    \"\"\"\n    Function to build a vocabulary from a list of sentences.\n\n    Args:\n        sentences (List[str]): containing input sentences\n\n    Returns:\n        word2idx: dict, mapping words to indices\n        idx2word: dict, mapping indices to words\n    \"\"\"\n\n    words = [word for sentence in sentences for word in sentence.split()]\n    word_count = Counter(words)\n\n    sorted_word_counts = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n\n    word2idx = {word: idx for idx, (word, _) in enumerate(sorted_word_counts, 2)}\n\n    word2idx[\"<pad>\"] = 0  # Reserved for padding\n    word2idx[\"<unk>\"] = 1  # Reserved for unknown words\n\n    idx2word = {idx: word for word, idx in word2idx.items()}\n    return word2idx, idx2word","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:59.378842Z","iopub.execute_input":"2024-11-25T00:52:59.379089Z","iopub.status.idle":"2024-11-25T00:52:59.388413Z","shell.execute_reply.started":"2024-11-25T00:52:59.379066Z","shell.execute_reply":"2024-11-25T00:52:59.387652Z"}},"outputs":[],"execution_count":35},{"id":"97c06594","cell_type":"markdown","source":"## Building the english & spanish vocabularies","metadata":{}},{"id":"7fa8738e","cell_type":"code","source":"eng_word2idx, eng_idx2word = build_vocab(eng_sentences)\nspa_word2idx, spa_idx2word = build_vocab(spa_sentences)\neng_vocab_size = len(eng_word2idx)\nspa_vocab_size = len(spa_word2idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:52:59.389408Z","iopub.execute_input":"2024-11-25T00:52:59.389642Z","iopub.status.idle":"2024-11-25T00:53:00.531444Z","shell.execute_reply.started":"2024-11-25T00:52:59.389619Z","shell.execute_reply":"2024-11-25T00:53:00.530489Z"}},"outputs":[],"execution_count":36},{"id":"79d6b633","cell_type":"code","source":"print(eng_vocab_size, spa_vocab_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:53:00.532561Z","iopub.execute_input":"2024-11-25T00:53:00.532874Z","iopub.status.idle":"2024-11-25T00:53:00.537168Z","shell.execute_reply.started":"2024-11-25T00:53:00.532847Z","shell.execute_reply":"2024-11-25T00:53:00.536264Z"}},"outputs":[{"name":"stdout","text":"27688 46991\n","output_type":"stream"}],"execution_count":37},{"id":"9dcc8786","cell_type":"markdown","source":"## EngSpaDataset","metadata":{}},{"id":"e564017c","cell_type":"code","source":"class EngSpaDataset(Dataset):\n    \"\"\"\n    English-Spanish dataset class designed to convert sentences into\n    word indices using the word-to-index dictionaries.\n\n    Attributes:\n        eng_sentences (List[str]): List of English sentences\n        spa_sentences (List[str]): List of Spanish sentences\n        eng_word2idx (dict): Dictionary to map English words to indices\n        spa_word2idx (dict): Dictionary to map Spanish words to indices\n    \"\"\"\n\n    def __init__(\n        self,\n        eng_sentences: List[str],\n        spa_sentences: List[str],\n        eng_word2idx: dict,\n        spa_word2idx: dict,\n    ):\n        self.eng_sentences = eng_sentences\n        self.spa_sentences = spa_sentences\n        self.eng_word2idx = eng_word2idx\n        self.spa_word2idx = spa_word2idx\n\n    def __len__(self):\n        \"\"\"\n        Computes the length of the dataset.\n\n        Returns:\n            int: The length of the dataset\n        \"\"\"\n\n        return len(self.eng_sentences)\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Gets an item from the dataset at the specified index.\n\n        Args:\n            idx (int): The index of the item to retrieve\n\n        Returns:\n            Tuple[torch.Tensor, torch.Tensor]: The English and Spanish sentence indices\n        \"\"\"\n\n        eng_sentence = self.eng_sentences[idx]\n        spa_sentence = self.spa_sentences[idx]\n\n        eng_idxs = [\n            self.eng_word2idx.get(word, self.eng_word2idx[\"<unk>\"])\n            for word in eng_sentence.split()\n        ]\n\n        spa_idxs = [\n            self.spa_word2idx.get(word, self.spa_word2idx[\"<unk>\"])\n            for word in spa_sentence.split()\n        ]\n\n        return torch.tensor(eng_idxs), torch.tensor(spa_idxs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:53:00.538347Z","iopub.execute_input":"2024-11-25T00:53:00.538786Z","iopub.status.idle":"2024-11-25T00:53:00.554166Z","shell.execute_reply.started":"2024-11-25T00:53:00.538749Z","shell.execute_reply":"2024-11-25T00:53:00.553368Z"}},"outputs":[],"execution_count":38},{"id":"fcff13ae","cell_type":"markdown","source":"## Collate Function","metadata":{}},{"id":"b579577b","cell_type":"code","source":"def collate_fn(\n    batch: List[Tuple[torch.Tensor, torch.Tensor]]\n) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Function to pad sequences in a batch to the same length.\n\n    Args:\n        batch (List[Tuple[torch.Tensor, torch.Tensor]]): The batch of data\n\n    Returns:\n        eng_batch: tensor, padded English sentences\n        spa_batch: tensor, padded Spanish sentences\n    \"\"\"\n\n    eng_batch, spa_batch = zip(*batch)\n    eng_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in eng_batch]\n    spa_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in spa_batch]\n\n    eng_batch = torch.nn.utils.rnn.pad_sequence(\n        eng_batch, batch_first=True, padding_value=0\n    )\n\n    spa_batch = torch.nn.utils.rnn.pad_sequence(\n        spa_batch, batch_first=True, padding_value=0\n    )\n\n    return eng_batch, spa_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:53:00.555132Z","iopub.execute_input":"2024-11-25T00:53:00.555369Z","iopub.status.idle":"2024-11-25T00:53:00.564406Z","shell.execute_reply.started":"2024-11-25T00:53:00.555346Z","shell.execute_reply":"2024-11-25T00:53:00.563645Z"}},"outputs":[],"execution_count":39},{"id":"e3708be0","cell_type":"markdown","source":"## Train Function","metadata":{}},{"id":"8d514b7c","cell_type":"code","source":"def train(model, dataloader, loss_function, optimiser, epochs):\n    \"\"\"\n    Training loop for the Transformer model.\n\n    Args:\n        model (Transformer): The Transformer model\n        dataloader (DataLoader): The DataLoader object\n        loss_function (nn.CrossEntropyLoss): The loss function\n        optimiser (optim.Adam): The optimiser\n        epochs (int): The number of epochs\n    \"\"\"\n\n    model.train()\n\n    for epoch in range(epochs):\n        total_loss = 0\n\n        for i, (eng_batch, spa_batch) in enumerate(dataloader):\n            eng_batch = eng_batch.to(device)\n            spa_batch = spa_batch.to(device)\n\n            target_input = spa_batch[:, :-1]\n            target_output = spa_batch[:, 1:].contiguous().view(-1)\n\n            optimiser.zero_grad()\n\n            output = model(eng_batch, target_input)\n            output = output.view(-1, output.size(-1))\n\n            loss = loss_function(output, target_output)\n\n            loss.backward()\n            optimiser.step()\n            total_loss += loss.item()\n\n        avg_loss = total_loss / len(dataloader)\n        print(f\"Epoch: {epoch}/{epochs}, Loss: {avg_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:53:00.565463Z","iopub.execute_input":"2024-11-25T00:53:00.565969Z","iopub.status.idle":"2024-11-25T00:53:00.577707Z","shell.execute_reply.started":"2024-11-25T00:53:00.565931Z","shell.execute_reply":"2024-11-25T00:53:00.576944Z"}},"outputs":[],"execution_count":40},{"id":"75eb533b","cell_type":"markdown","source":"## Data Loader Parameters","metadata":{}},{"id":"2379ea72","cell_type":"code","source":"BATCH_SIZE = 64","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:53:00.578705Z","iopub.execute_input":"2024-11-25T00:53:00.578955Z","iopub.status.idle":"2024-11-25T00:53:00.586996Z","shell.execute_reply.started":"2024-11-25T00:53:00.578932Z","shell.execute_reply":"2024-11-25T00:53:00.586338Z"}},"outputs":[],"execution_count":41},{"id":"ee4affae","cell_type":"code","source":"dataset = EngSpaDataset(eng_sentences, spa_sentences, eng_word2idx, spa_word2idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:53:00.587719Z","iopub.execute_input":"2024-11-25T00:53:00.587977Z","iopub.status.idle":"2024-11-25T00:53:00.595332Z","shell.execute_reply.started":"2024-11-25T00:53:00.587953Z","shell.execute_reply":"2024-11-25T00:53:00.594718Z"}},"outputs":[],"execution_count":42},{"id":"13079c5f","cell_type":"code","source":"dataloader = DataLoader(\n    dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:53:00.596163Z","iopub.execute_input":"2024-11-25T00:53:00.596407Z","iopub.status.idle":"2024-11-25T00:53:00.610828Z","shell.execute_reply.started":"2024-11-25T00:53:00.596370Z","shell.execute_reply":"2024-11-25T00:53:00.610012Z"}},"outputs":[],"execution_count":43},{"id":"85f6802e","cell_type":"markdown","source":"## Training the model","metadata":{}},{"id":"e08eef6a","cell_type":"code","source":"model = Transformer(\n    d_model=512,\n    num_heads=8,\n    d_ff=2048,\n    num_layers=6,\n    input_vocab_size=eng_vocab_size,\n    target_vocab_size=spa_vocab_size,\n    max_len=MAX_SEQ_LEN,\n    dropout=0.1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:53:00.611719Z","iopub.execute_input":"2024-11-25T00:53:00.612031Z","iopub.status.idle":"2024-11-25T00:53:01.565539Z","shell.execute_reply.started":"2024-11-25T00:53:00.611997Z","shell.execute_reply":"2024-11-25T00:53:01.564384Z"}},"outputs":[],"execution_count":44},{"id":"a1181a12","cell_type":"code","source":"model = model.to(device)\nloss_function = nn.CrossEntropyLoss(ignore_index=0)\noptimiser = optim.Adam(model.parameters(), lr=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:53:01.566699Z","iopub.execute_input":"2024-11-25T00:53:01.566957Z","iopub.status.idle":"2024-11-25T00:53:02.530263Z","shell.execute_reply.started":"2024-11-25T00:53:01.566932Z","shell.execute_reply":"2024-11-25T00:53:02.529529Z"}},"outputs":[],"execution_count":45},{"id":"14e265e9","cell_type":"code","source":"train(model, dataloader, loss_function, optimiser, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T00:53:02.531325Z","iopub.execute_input":"2024-11-25T00:53:02.531838Z","iopub.status.idle":"2024-11-25T02:36:28.469971Z","shell.execute_reply.started":"2024-11-25T00:53:02.531800Z","shell.execute_reply":"2024-11-25T02:36:28.469186Z"}},"outputs":[{"name":"stdout","text":"Epoch: 0/10, Loss: 3.5978\nEpoch: 1/10, Loss: 2.2009\nEpoch: 2/10, Loss: 1.7008\nEpoch: 3/10, Loss: 1.3739\nEpoch: 4/10, Loss: 1.1242\nEpoch: 5/10, Loss: 0.9223\nEpoch: 6/10, Loss: 0.7568\nEpoch: 7/10, Loss: 0.6298\nEpoch: 8/10, Loss: 0.5343\nEpoch: 9/10, Loss: 0.4664\n","output_type":"stream"}],"execution_count":46},{"id":"365b2bcf","cell_type":"markdown","source":"## Auxiliary Functions","metadata":{}},{"id":"50740746","cell_type":"code","source":"def sentence_to_indices(sentence, word2idx):\n    \"\"\"\n    Converts a sentence into a list of indices using a word-to-index dictionary.\n\n    Args:\n        sentence (str): The sentence to convert.\n        word2idx (dict): The dictionary mapping words to indices.\n\n    Returns:to\n        list: A list of indices corresponding to the words in the sentence.\n    \"\"\"\n\n    return [word2idx.get(word, word2idx[\"<unk>\"]) for word in sentence.split()]\n\n\ndef indices_to_sentence(indices, idx2word):\n    \"\"\"\n    Converts a list of indices back into a sentence using an index-to-word dictionary.\n\n    Args:\n        indices (list): The list of indices to convert.\n        idx2word (dict): The dictionary mapping indices to words.\n\n    Returns:\n        str: The sentence corresponding to the indices.\n    \"\"\"\n\n    return \" \".join(\n        [\n            idx2word[idx]\n            for idx in indices\n            if idx in idx2word and idx2word[idx] != \"<pad>\"\n        ]\n    )\n\n\ndef translate_sentence(\n    model, sentence, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device=\"cpu\"\n) -> str:\n    \"\"\"\n    Translates a sentence from English to Spanish using the trained Transformer model.\n\n    Args:\n        model (nn.Module): The trained Transformer model.\n        sentence (str): The English sentence to translate.\n        eng_word2idx (dict): The dictionary mapping English words to indices.\n        spa_idx2word (dict): The dictionary mapping Spanish indices to words.\n        max_len (int): The maximum length of the translated sentence.\n        device (str): The device to run the model on ('cpu' or 'cuda').\n\n    Returns:\n        str: The translated Spanish sentence.\n    \"\"\"\n\n    model.eval()\n\n    sentence = preprocess_sentence(sentence)\n    input_indices = sentence_to_indices(sentence, eng_word2idx)\n    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)\n\n    tgt_indices = [spa_word2idx[\"<sos>\"]]\n    tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        for _ in range(max_len):\n            output = model(input_tensor, tgt_tensor)\n\n            output = output.squeeze(0)\n\n            next_token = output.argmax(dim=-1)[-1].item()\n            tgt_indices.append(next_token)\n            tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n\n            if next_token == spa_word2idx[\"<eos>\"]:\n                break\n\n    return indices_to_sentence(tgt_indices, spa_idx2word)","metadata":{"code_folding":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T02:36:28.471217Z","iopub.execute_input":"2024-11-25T02:36:28.471494Z","iopub.status.idle":"2024-11-25T02:36:28.479510Z","shell.execute_reply.started":"2024-11-25T02:36:28.471468Z","shell.execute_reply":"2024-11-25T02:36:28.478659Z"}},"outputs":[],"execution_count":47},{"id":"13954aa5","cell_type":"markdown","source":"## Evaluator","metadata":{}},{"id":"c2c0db72","cell_type":"code","source":"def evaluate_translations(\n    model, sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device=\"cpu\"\n):\n    \"\"\"\n    Evaluates translations for a list of sentences using the trained Transformer model.\n\n    Args:\n        model (nn.Module): The trained Transformer model.\n        sentences (list): A list of sentences to translate.\n        eng_word2idx (dict): The dictionary mapping English words to indices.\n        spa_idx2word (dict): The dictionary mapping Spanish indices to words.\n        max_len (int): The maximum length of the translated sentence.\n        device (str): The device to run the model on ('cpu' or 'cuda').\n    \"\"\"\n\n    for sentence in sentences:\n        translation = translate_sentence(\n            model, sentence, eng_word2idx, spa_idx2word, max_len, device\n        )\n\n        print(f\"Input sentence: {sentence}\")\n        print(f\"Traducción: {translation}\")\n        print()","metadata":{"code_folding":[15],"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T02:36:28.480655Z","iopub.execute_input":"2024-11-25T02:36:28.480904Z","iopub.status.idle":"2024-11-25T02:36:28.494928Z","shell.execute_reply.started":"2024-11-25T02:36:28.480881Z","shell.execute_reply":"2024-11-25T02:36:28.494188Z"}},"outputs":[],"execution_count":48},{"id":"c11f9e36","cell_type":"markdown","source":"## Testing the model","metadata":{}},{"id":"35742176","cell_type":"code","source":"test_sentences = [\n    \"Hello, how are you?\",\n    \"I am learning artificial intelligence.\",\n    \"Artificial intelligence is great.\",\n    \"Good night!\",\n    \"The weather is beautiful today.\",\n    \"Could you please help me find my keys?\",\n    \"She works at a technology company in Silicon Valley.\",\n    \"Remember to drink plenty of water throughout the day.\",\n    \"My favorite season is autumn because of the colorful leaves.\",\n    \"We should meet for coffee next Tuesday afternoon.\",\n    \"The new restaurant downtown serves amazing Italian food.\",\n    \"The children are playing in the park with their friends.\",\n    \"Don't forget to submit your assignment by Friday.\",\n    \"The concert last night was absolutely incredible.\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T02:37:38.458774Z","iopub.execute_input":"2024-11-25T02:37:38.459130Z","iopub.status.idle":"2024-11-25T02:37:38.463668Z","shell.execute_reply.started":"2024-11-25T02:37:38.459100Z","shell.execute_reply":"2024-11-25T02:37:38.462770Z"}},"outputs":[],"execution_count":52},{"id":"5e703f2f","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T02:36:28.506338Z","iopub.execute_input":"2024-11-25T02:36:28.506673Z","iopub.status.idle":"2024-11-25T02:36:28.527409Z","shell.execute_reply.started":"2024-11-25T02:36:28.506637Z","shell.execute_reply":"2024-11-25T02:36:28.526583Z"}},"outputs":[],"execution_count":50},{"id":"06836633","cell_type":"code","source":"evaluate_translations(\n    model,\n    test_sentences,\n    eng_word2idx,\n    spa_idx2word,\n    max_len=MAX_SEQ_LEN,\n    device=device,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T02:37:41.167761Z","iopub.execute_input":"2024-11-25T02:37:41.168086Z","iopub.status.idle":"2024-11-25T02:37:42.365368Z","shell.execute_reply.started":"2024-11-25T02:37:41.168061Z","shell.execute_reply":"2024-11-25T02:37:42.364661Z"}},"outputs":[{"name":"stdout","text":"Input sentence: Hello, how are you?\nTraducción: <sos> hola como estas <eos>\n\nInput sentence: I am learning artificial intelligence.\nTraducción: <sos> estoy aprendiendo inteligencia artificial <eos>\n\nInput sentence: Artificial intelligence is great.\nTraducción: <sos> la inteligencia artificial es muy artificial <eos>\n\nInput sentence: Good night!\nTraducción: <sos> buenas noches <eos>\n\nInput sentence: The weather is beautiful today.\nTraducción: <sos> hoy hace un buen tiempo <eos>\n\nInput sentence: Could you please help me find my keys?\nTraducción: <sos> podrias ayudarme a encontrar mis llaves por favor <eos>\n\nInput sentence: She works at a technology company in Silicon Valley.\nTraducción: <sos> ella trabaja en una empresa de tecnologia de gravedad <eos>\n\nInput sentence: Remember to drink plenty of water throughout the day.\nTraducción: <sos> no te olvides de tomar mucha agua por dia <eos>\n\nInput sentence: My favorite season is autumn because of the colorful leaves.\nTraducción: <sos> mi oto o favorita es la estacion favorita de hojas <eos>\n\nInput sentence: We should meet for coffee next Tuesday afternoon.\nTraducción: <sos> nos vemos el cafe por la tarde para el proximo martes <eos>\n\nInput sentence: The new restaurant downtown serves amazing Italian food.\nTraducción: <sos> el nuevo restaurante sirve comida china en el centro de la ciudad de la tierra <eos>\n\nInput sentence: The children are playing in the park with their friends.\nTraducción: <sos> los ni os estan jugando en el parque con sus amigos <eos>\n\nInput sentence: Don't forget to submit your assignment by Friday.\nTraducción: <sos> no olvides entregar tu tarea en el viernes <eos>\n\nInput sentence: The concert last night was absolutely incredible.\nTraducción: <sos> el concierto fue absolutamente increible anoche <eos>\n\n","output_type":"stream"}],"execution_count":53}]}